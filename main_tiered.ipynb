{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## CPEA\n",
    "### Tiered imagenet training/testing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b146a710ee0acefd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "295b0e69343cdbae"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from cpea import CPEA\n",
    "from models.backbones import BackBone\n",
    "from dataloader.samplers import CategoriesSampler\n",
    "from utils import ensure_path, Averager, count_acc, compute_confidence_interval\n",
    "from tensorboardX import SummaryWriter\n",
    "from types import SimpleNamespace\n",
    "import gc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-31T11:30:53.849289400Z",
     "start_time": "2024-08-31T11:30:53.833656400Z"
    }
   },
   "id": "94c0fdbe549fb2bd"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-31T11:30:55.250735100Z",
     "start_time": "2024-08-31T11:30:55.100004100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 1            |        cudaMalloc retries: 1         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |   2623 MiB |   2667 MiB |   4658 MiB |   2034 MiB |\n",
      "|       from large pool |   2614 MiB |   2658 MiB |   4649 MiB |   2034 MiB |\n",
      "|       from small pool |      9 MiB |      9 MiB |      9 MiB |      0 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |   2623 MiB |   2667 MiB |   4658 MiB |   2034 MiB |\n",
      "|       from large pool |   2614 MiB |   2658 MiB |   4649 MiB |   2034 MiB |\n",
      "|       from small pool |      9 MiB |      9 MiB |      9 MiB |      0 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |   2616 MiB |   2660 MiB |   4646 MiB |   2029 MiB |\n",
      "|       from large pool |   2607 MiB |   2651 MiB |   4637 MiB |   2029 MiB |\n",
      "|       from small pool |      8 MiB |      8 MiB |      8 MiB |      0 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |   2748 MiB |   2770 MiB |   2834 MiB |  88064 KiB |\n",
      "|       from large pool |   2738 MiB |   2760 MiB |   2824 MiB |  88064 KiB |\n",
      "|       from small pool |     10 MiB |     10 MiB |     10 MiB |      0 KiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory | 127263 KiB | 149542 KiB |   1745 MiB |   1621 MiB |\n",
      "|       from large pool | 126257 KiB | 148420 KiB |   1737 MiB |   1613 MiB |\n",
      "|       from small pool |   1006 KiB |   2247 KiB |      8 MiB |      7 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |     456    |     456    |     656    |     200    |\n",
      "|       from large pool |     232    |     234    |     402    |     170    |\n",
      "|       from small pool |     224    |     224    |     254    |      30    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |     456    |     456    |     656    |     200    |\n",
      "|       from large pool |     232    |     234    |     402    |     170    |\n",
      "|       from small pool |     224    |     224    |     254    |      30    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |      69    |      70    |      72    |       3    |\n",
      "|       from large pool |      64    |      65    |      67    |       3    |\n",
      "|       from small pool |       5    |       5    |       5    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |      50    |      51    |     190    |     140    |\n",
      "|       from large pool |      47    |      48    |     155    |     108    |\n",
      "|       from small pool |       3    |       4    |      35    |      32    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n"
     ]
    }
   ],
   "source": [
    "args = SimpleNamespace(\n",
    "    max_epoch=2,\n",
    "    way=5,\n",
    "    test_way=5,\n",
    "    shot=1,\n",
    "    query=15,\n",
    "    lr=0.00001,\n",
    "    lr_mul=100,\n",
    "    step_size=5,\n",
    "    gamma=0.5,\n",
    "    model_type='small',\n",
    "    dataset='FC100',\n",
    "    init_weights='./initialization/tieredimagenet/checkpoint0800.pth',\n",
    "    gpu='0',\n",
    "    exp='CPEA'\n",
    ")\n",
    "save_path = '-'.join([args.exp, args.dataset, args.model_type])\n",
    "args.save_path = osp.join('./results', save_path)\n",
    "ensure_path(args.save_path)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15481258d7bc13f7"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jurij\\PycharmProjects\\CPEA\\CPEA\\datasets\\fc100\\\n",
      "C:\\Users\\Jurij\\PycharmProjects\\CPEA\\CPEA\\datasets\\fc100\\\n"
     ]
    }
   ],
   "source": [
    "from dataloader.fc100 import FC100 as Dataset\n",
    "\n",
    "trainset = Dataset('train', args)\n",
    "train_sampler = CategoriesSampler(trainset.label, 10, args.way, args.shot + args.query)\n",
    "train_loader = DataLoader(dataset=trainset, batch_sampler=train_sampler, num_workers=8, pin_memory=True)\n",
    "\n",
    "valset = Dataset('val', args)\n",
    "val_sampler = CategoriesSampler(valset.label, 10, args.test_way, args.shot + args.query)\n",
    "val_loader = DataLoader(dataset=valset, batch_sampler=val_sampler, num_workers=8, pin_memory=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-31T11:30:57.798543800Z",
     "start_time": "2024-08-31T11:30:57.317934300Z"
    }
   },
   "id": "ff8aae758d8a5422"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62eeb02f520b848e"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using small\n"
     ]
    }
   ],
   "source": [
    "model = BackBone(args)\n",
    "dense_predict_network = CPEA()\n",
    "\n",
    "optimizer = torch.optim.Adam([{'params': model.encoder.parameters()}], lr=args.lr, weight_decay=0.001)\n",
    "print('Using {}'.format(args.model_type))\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=args.step_size, gamma=args.gamma)\n",
    "\n",
    "dense_predict_network_optim = torch.optim.Adam(dense_predict_network.parameters(), lr=args.lr * args.lr_mul,\n",
    "                                               weight_decay=0.001)\n",
    "dense_predict_network_scheduler = torch.optim.lr_scheduler.StepLR(dense_predict_network_optim,\n",
    "                                                                  step_size=args.step_size, gamma=args.gamma)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-31T11:31:02.144765500Z",
     "start_time": "2024-08-31T11:31:00.894110800Z"
    }
   },
   "id": "23886e570fda22c8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initialize pretrained model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23ca82d090f124e6"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# load pre-trained model (no FC weights)\n",
    "model_dict = model.state_dict()\n",
    "# print(model_dict.keys())\n",
    "if args.init_weights is not None:\n",
    "    pretrained_dict = torch.load(args.init_weights, map_location='cpu')['teacher']\n",
    "    # print(pretrained_dict.keys())\n",
    "    pretrained_dict = {k.replace('backbone', 'encoder'): v for k, v in pretrained_dict.items()}\n",
    "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "    model_dict.update(pretrained_dict)\n",
    "    model.load_state_dict(model_dict)\n",
    "    # print(pretrained_dict.keys())\n",
    "\n",
    "'''\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    model = model.cuda()\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    dense_predict_network = dense_predict_network.cuda()\n",
    "'''\n",
    "\n",
    "def save_model(name):\n",
    "    torch.save(dict(params=model.state_dict()), osp.join(args.save_path, name + '.pth'))\n",
    "    torch.save(dict(params=dense_predict_network.state_dict()),\n",
    "               osp.join(args.save_path, name + '_dense_predict.pth'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-31T11:31:08.511633700Z",
     "start_time": "2024-08-31T11:31:07.948554200Z"
    }
   },
   "id": "cc57e728743c1cbb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initialize logging"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa17a288220d43ed"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "trlog = {'args': vars(args), 'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': [], 'max_acc': 0.0,\n",
    "         'max_acc_epoch': 0}\n",
    "global_count = 0\n",
    "writer = SummaryWriter(comment=args.save_path)\n",
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-31T11:31:10.269236700Z",
     "start_time": "2024-08-31T11:31:10.143490500Z"
    }
   },
   "id": "1749d40511748605"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a2e04b83e717a5f"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "3049"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-31T11:49:33.986990400Z",
     "start_time": "2024-08-31T11:49:31.020771300Z"
    }
   },
   "id": "3c62709f5f4d5cf8"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "before data load\n",
      "after data load\n",
      "before model\n",
      "after model\n",
      "torch.Size([75, 197, 384])\n",
      "predict network\n",
      "epoch 1, train 1/10, loss=1.6092 acc=0.1867\n",
      "before data load\n",
      "after data load\n",
      "before model\n",
      "after model\n",
      "torch.Size([75, 197, 384])\n",
      "predict network\n",
      "epoch 1, train 2/10, loss=9.9821 acc=0.1600\n",
      "before data load\n",
      "after data load\n",
      "before model\n",
      "after model\n",
      "torch.Size([75, 197, 384])\n",
      "predict network\n",
      "epoch 1, train 3/10, loss=3.2281 acc=0.1333\n",
      "before data load\n",
      "after data load\n",
      "before model\n",
      "after model\n",
      "torch.Size([75, 197, 384])\n",
      "predict network\n",
      "epoch 1, train 4/10, loss=1.9901 acc=0.1867\n",
      "before data load\n",
      "after data load\n",
      "before model\n",
      "after model\n",
      "torch.Size([75, 197, 384])\n",
      "predict network\n",
      "epoch 1, train 5/10, loss=1.7098 acc=0.2533\n",
      "before data load\n",
      "after data load\n",
      "before model\n",
      "after model\n",
      "torch.Size([75, 197, 384])\n",
      "predict network\n",
      "epoch 1, train 6/10, loss=1.8045 acc=0.2000\n",
      "before data load\n",
      "after data load\n",
      "before model\n",
      "after model\n",
      "torch.Size([75, 197, 384])\n",
      "predict network\n",
      "epoch 1, train 7/10, loss=1.7717 acc=0.2800\n",
      "before data load\n",
      "after data load\n",
      "before model\n",
      "after model\n",
      "torch.Size([75, 197, 384])\n",
      "predict network\n",
      "epoch 1, train 8/10, loss=1.7607 acc=0.1867\n",
      "before data load\n",
      "after data load\n",
      "before model\n",
      "after model\n",
      "torch.Size([75, 197, 384])\n",
      "predict network\n",
      "epoch 1, train 9/10, loss=1.6322 acc=0.1600\n",
      "before data load\n",
      "after data load\n",
      "before model\n",
      "after model\n",
      "torch.Size([75, 197, 384])\n",
      "predict network\n",
      "epoch 1, train 10/10, loss=1.6454 acc=0.2000\n",
      "best epoch 0, best val acc=0.0000\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n",
      "torch.Size([75, 197, 384])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_18900\\669262993.py\u001B[0m in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     76\u001B[0m             \u001B[0mp\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshot\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtest_way\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     77\u001B[0m             \u001B[0mdata_shot\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata_query\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[0mp\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mp\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 78\u001B[1;33m             \u001B[0mfeat_shot\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfeat_query\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata_shot\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata_query\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     79\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     80\u001B[0m             \u001B[0mresults\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdense_predict_network\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfeat_query\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfeat_shot\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# Q x S\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\few-shot\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1499\u001B[0m                 \u001B[1;32mor\u001B[0m \u001B[0m_global_backward_pre_hooks\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0m_global_backward_hooks\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1500\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1502\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1503\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\CPEA\\CPEA\\models\\backbones.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, support, query)\u001B[0m\n\u001B[0;32m     17\u001B[0m         \u001B[1;31m# feature extraction\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     18\u001B[0m         \u001B[0msupport\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mencoder\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msupport\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 19\u001B[1;33m         \u001B[0mquery\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mencoder\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mquery\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     20\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0msupport\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mquery\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\few-shot\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1499\u001B[0m                 \u001B[1;32mor\u001B[0m \u001B[0m_global_backward_pre_hooks\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0m_global_backward_hooks\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1500\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1502\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1503\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\CPEA\\CPEA\\models\\vit.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, x, return_all_tokens, mask)\u001B[0m\n\u001B[0;32m    237\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    238\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mblk\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mblocks\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 239\u001B[1;33m             \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mblk\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    240\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    241\u001B[0m         \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnorm\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\few-shot\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1499\u001B[0m                 \u001B[1;32mor\u001B[0m \u001B[0m_global_backward_pre_hooks\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0m_global_backward_hooks\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1500\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1502\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1503\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\CPEA\\CPEA\\models\\vit.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, x, return_attention)\u001B[0m\n\u001B[0;32m    109\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    110\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreturn_attention\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 111\u001B[1;33m         \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mattn\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mattn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnorm1\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    112\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mreturn_attention\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    113\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mattn\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\few-shot\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1499\u001B[0m                 \u001B[1;32mor\u001B[0m \u001B[0m_global_backward_pre_hooks\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0m_global_backward_hooks\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1500\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1502\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1503\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\CPEA\\CPEA\\models\\vit.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     80\u001B[0m         \u001B[0mq\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mk\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mv\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mqkv\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mqkv\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mqkv\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     81\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 82\u001B[1;33m         \u001B[0mattn\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mq\u001B[0m \u001B[1;33m@\u001B[0m \u001B[0mk\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtranspose\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mscale\u001B[0m   \u001B[1;31m# shape [N, n_h, N, N]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     83\u001B[0m         \u001B[0mattn\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mattn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msoftmax\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdim\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     84\u001B[0m         \u001B[0mattn\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mattn_drop\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mattn\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, args.max_epoch + 1):\n",
    "    print(epoch)\n",
    "    # lr_scheduler.step()\n",
    "    # dense_predict_network_scheduler.step()\n",
    "    model.train()\n",
    "    dense_predict_network.train()\n",
    "    tl = Averager()\n",
    "    ta = Averager()\n",
    "\n",
    "    for i, batch in enumerate(train_loader, 1):\n",
    "        # zero gradient\n",
    "        optimizer.zero_grad()\n",
    "        dense_predict_network_optim.zero_grad()\n",
    "\n",
    "        # forward and backward\n",
    "        global_count = global_count + 1\n",
    "        # if torch.cuda.is_available():\n",
    "        #     data, _ = [_.cuda() for _ in batch]\n",
    "        # else:\n",
    "        print(\"before data load\")\n",
    "        data = batch[0]\n",
    "        print(\"after data load\")\n",
    "\n",
    "        p = args.shot * args.way\n",
    "        data_shot, data_query = data[:p], data[p:]\n",
    "        print(\"before model\")\n",
    "        feat_shot, feat_query = model(data_shot, data_query)\n",
    "        print(\"after model\")\n",
    "        results, _ = dense_predict_network(feat_query, feat_shot, args)\n",
    "        print(\"predict network\")\n",
    "        results = torch.cat(results, dim=0)  # Q x S\n",
    "        # label = torch.arange(args.way).repeat(args.query).long().to('cuda')\n",
    "        label = torch.arange(args.way).repeat(args.query).long()\n",
    "\n",
    "        eps = 0.1\n",
    "        one_hot = torch.zeros_like(results).scatter(1, label.view(-1, 1), 1)\n",
    "        one_hot = one_hot * (1 - eps) + (1 - one_hot) * eps / (args.way - 1)\n",
    "        log_prb = F.log_softmax(results, dim=1)\n",
    "\n",
    "        loss = -(one_hot * log_prb).sum(dim=1)\n",
    "        loss = loss.mean()\n",
    "\n",
    "        acc = count_acc(results.data, label)\n",
    "        writer.add_scalar('data/loss', float(loss), global_count)\n",
    "        writer.add_scalar('data/acc', float(acc), global_count)\n",
    "        print('epoch {}, train {}/{}, loss={:.4f} acc={:.4f}'.format(epoch, i, len(train_loader), loss.item(), acc))\n",
    "\n",
    "        tl.add(loss.item())\n",
    "        ta.add(acc)\n",
    "\n",
    "        loss_total = loss\n",
    "\n",
    "        loss_total.backward()\n",
    "        optimizer.step()\n",
    "        dense_predict_network_optim.step()\n",
    "\n",
    "    lr_scheduler.step()\n",
    "    dense_predict_network_scheduler.step()\n",
    "\n",
    "    tl = tl.item()\n",
    "    ta = ta.item()\n",
    "\n",
    "    model.eval()\n",
    "    dense_predict_network.eval()\n",
    "\n",
    "    vl = Averager()\n",
    "    va = Averager()\n",
    "\n",
    "    print('best epoch {}, best val acc={:.4f}'.format(trlog['max_acc_epoch'], trlog['max_acc']))\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(val_loader, 1):\n",
    "            # if torch.cuda.is_available():\n",
    "            #     data, _ = [_.cuda() for _ in batch]\n",
    "            # else:\n",
    "            data = batch[0]\n",
    "            p = args.shot * args.test_way\n",
    "            data_shot, data_query = data[:p], data[p:]\n",
    "            feat_shot, feat_query = model(data_shot, data_query)\n",
    "\n",
    "            results, _ = dense_predict_network(feat_query, feat_shot, args)  # Q x S\n",
    "\n",
    "            results = [torch.mean(idx, dim=0, keepdim=True) for idx in results]\n",
    "\n",
    "            results = torch.cat(results, dim=0)  # Q x S\n",
    "            # label = torch.arange(args.test_way).repeat(args.query).long().to('cuda')\n",
    "            label = torch.arange(args.test_way).repeat(args.query).long()\n",
    "\n",
    "            loss = F.cross_entropy(results, label)\n",
    "            acc = count_acc(results.data, label)\n",
    "            vl.add(loss.item())\n",
    "            va.add(acc)\n",
    "\n",
    "    vl = vl.item()\n",
    "    va = va.item()\n",
    "    writer.add_scalar('data/val_loss', float(vl), epoch)\n",
    "    writer.add_scalar('data/val_acc', float(va), epoch)\n",
    "    print('epoch {}, val, loss={:.4f} acc={:.4f}'.format(epoch, vl, va))\n",
    "\n",
    "    if va >= trlog['max_acc']:\n",
    "        trlog['max_acc'] = va\n",
    "        trlog['max_acc_epoch'] = epoch\n",
    "        save_model('max_acc')\n",
    "\n",
    "    trlog['train_loss'].append(tl)\n",
    "    trlog['train_acc'].append(ta)\n",
    "    trlog['val_loss'].append(vl)\n",
    "    trlog['val_acc'].append(va)\n",
    "\n",
    "    torch.save(trlog, osp.join(args.save_path, 'trlog'))\n",
    "\n",
    "    save_model('epoch-last')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-31T13:43:25.952307Z",
     "start_time": "2024-08-31T11:49:34.880100200Z"
    }
   },
   "id": "c5f29ba2027d8316"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Testing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d1f2e1024fa6dff"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trlog = torch.load(osp.join(args.save_path, 'trlog'))\n",
    "test_set = Dataset('test', args)\n",
    "sampler = CategoriesSampler(test_set.label, 1000, args.test_way, args.shot + args.query)\n",
    "loader = DataLoader(test_set, batch_sampler=sampler, num_workers=8, pin_memory=True)\n",
    "test_acc_record = np.zeros((1000,))\n",
    "\n",
    "model.load_state_dict(torch.load(osp.join(args.save_path, 'max_acc' + '.pth'))['params'])\n",
    "model.eval()\n",
    "\n",
    "dense_predict_network.load_state_dict(\n",
    "    torch.load(osp.join(args.save_path, 'max_acc' + '_dense_predict.pth'))['params'])\n",
    "dense_predict_network.eval()\n",
    "\n",
    "ave_acc = Averager()\n",
    "label = torch.arange(args.test_way).repeat(args.query)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(loader, 1):\n",
    "        if torch.cuda.is_available():\n",
    "            data, _ = [_.cuda() for _ in batch]\n",
    "        else:\n",
    "            data = batch[0]\n",
    "        k = args.test_way * args.shot\n",
    "        data_shot, data_query = data[:k], data[k:]\n",
    "        feat_shot, feat_query = model(data_shot, data_query)\n",
    "\n",
    "        results, _ = dense_predict_network(feat_query, feat_shot, args)  # Q x S\n",
    "        results = [torch.mean(idx, dim=0, keepdim=True) for idx in results]\n",
    "        results = torch.cat(results, dim=0)  # Q x S\n",
    "        label = torch.arange(args.test_way).repeat(args.query).long().to('cuda')\n",
    "\n",
    "        acc = count_acc(results.data, label)\n",
    "        ave_acc.add(acc)\n",
    "        test_acc_record[i - 1] = acc\n",
    "        print('batch {}: acc {:.2f}({:.2f})'.format(i, ave_acc.item() * 100, acc * 100))\n",
    "\n",
    "m, pm = compute_confidence_interval(test_acc_record)\n",
    "print('Val Best Epoch {}, Acc {:.4f}'.format(trlog['max_acc_epoch'], trlog['max_acc']))\n",
    "print('Test Acc {:.4f} + {:.4f}'.format(m, pm))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c84b74f38b6ad4f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
