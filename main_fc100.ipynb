{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## CPEA\n",
    "### Tiered imagenet training/testing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b146a710ee0acefd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "295b0e69343cdbae"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from cpea import CPEA\n",
    "from models.backbones import BackBone\n",
    "from dataloader.samplers import CategoriesSampler\n",
    "from utils import ensure_path, Averager, count_acc, compute_confidence_interval\n",
    "from tensorboardX import SummaryWriter\n",
    "from types import SimpleNamespace\n",
    "import gc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-02T15:44:56.882825800Z",
     "start_time": "2024-09-02T15:44:42.904238Z"
    }
   },
   "id": "94c0fdbe549fb2bd"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-02T15:45:02.516923Z",
     "start_time": "2024-09-02T15:44:59.630200100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n"
     ]
    }
   ],
   "source": [
    "args = SimpleNamespace(\n",
    "    max_epoch=2,\n",
    "    way=5,\n",
    "    test_way=5,\n",
    "    shot=1,\n",
    "    query=15,\n",
    "    lr=0.00001,\n",
    "    lr_mul=100,\n",
    "    step_size=5,\n",
    "    gamma=0.5,\n",
    "    model_type='small',\n",
    "    dataset='FC100',\n",
    "    init_weights='./initialization/fc100/checkpoint1600.pth',\n",
    "    gpu='0',\n",
    "    exp='CPEA'\n",
    ")\n",
    "save_path = '-'.join([args.exp, args.dataset, args.model_type])\n",
    "args.save_path = osp.join('./results', save_path)\n",
    "ensure_path(args.save_path)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15481258d7bc13f7"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from dataloader.fc100 import FC100 as Dataset\n",
    "\n",
    "trainset = Dataset('train', args)\n",
    "train_sampler = CategoriesSampler(trainset.label, 10, args.way, args.shot + args.query)\n",
    "train_loader = DataLoader(dataset=trainset, batch_sampler=train_sampler, num_workers=8, pin_memory=True)\n",
    "\n",
    "valset = Dataset('val', args)\n",
    "val_sampler = CategoriesSampler(valset.label, 10, args.test_way, args.shot + args.query)\n",
    "val_loader = DataLoader(dataset=valset, batch_sampler=val_sampler, num_workers=8, pin_memory=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-02T15:55:35.921679100Z",
     "start_time": "2024-09-02T15:55:31.956689400Z"
    }
   },
   "id": "ff8aae758d8a5422"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62eeb02f520b848e"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using small\n"
     ]
    }
   ],
   "source": [
    "model = BackBone(args)\n",
    "dense_predict_network = CPEA()\n",
    "\n",
    "optimizer = torch.optim.Adam([{'params': model.encoder.parameters()}], lr=args.lr, weight_decay=0.001)\n",
    "print('Using {}'.format(args.model_type))\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=args.step_size, gamma=args.gamma)\n",
    "\n",
    "dense_predict_network_optim = torch.optim.Adam(dense_predict_network.parameters(), lr=args.lr * args.lr_mul,\n",
    "                                               weight_decay=0.001)\n",
    "dense_predict_network_scheduler = torch.optim.lr_scheduler.StepLR(dense_predict_network_optim,\n",
    "                                                                  step_size=args.step_size, gamma=args.gamma)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-01T13:51:31.342335200Z",
     "start_time": "2024-09-01T13:51:27.768090300Z"
    }
   },
   "id": "23886e570fda22c8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from cpea_hierarchical import HierarchicalCPEA as HCPEA\n",
    "\n",
    "\n",
    "model = BackBone(args)\n",
    "dense_predict_network = HCPEA(CPEA, 75, 60, 12)\n",
    "\n",
    "optimizer = torch.optim.Adam([{'params': model.encoder.parameters()}], lr=args.lr, weight_decay=0.001)\n",
    "print('Using {}'.format(args.model_type))\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=args.step_size, gamma=args.gamma)\n",
    "\n",
    "dense_predict_network_optim = torch.optim.Adam(dense_predict_network.parameters(), lr=args.lr * args.lr_mul,\n",
    "                                               weight_decay=0.001)\n",
    "dense_predict_network_scheduler = torch.optim.lr_scheduler.StepLR(dense_predict_network_optim,\n",
    "                                                                  step_size=args.step_size, gamma=args.gamma)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e5aad0dd481077fa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initialize pretrained model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23ca82d090f124e6"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# load pre-trained model (no FC weights)\n",
    "model_dict = model.state_dict()\n",
    "# print(model_dict.keys())\n",
    "if args.init_weights is not None:\n",
    "    pretrained_dict = torch.load(args.init_weights, map_location='cpu')['teacher']\n",
    "    # print(pretrained_dict.keys())\n",
    "    pretrained_dict = {k.replace('backbone', 'encoder'): v for k, v in pretrained_dict.items()}\n",
    "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "    model_dict.update(pretrained_dict)\n",
    "    model.load_state_dict(model_dict)\n",
    "    # print(pretrained_dict.keys())\n",
    "\n",
    "'''\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    model = model.cuda()\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    dense_predict_network = dense_predict_network.cuda()\n",
    "'''\n",
    "\n",
    "def save_model(name):\n",
    "    torch.save(dict(params=model.state_dict()), osp.join(args.save_path, name + '.pth'))\n",
    "    torch.save(dict(params=dense_predict_network.state_dict()),\n",
    "               osp.join(args.save_path, name + '_dense_predict.pth'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-01T13:51:33.832320500Z",
     "start_time": "2024-09-01T13:51:32.512311Z"
    }
   },
   "id": "cc57e728743c1cbb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initialize logging"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa17a288220d43ed"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "trlog = {'args': vars(args), 'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': [], 'max_acc': 0.0,\n",
    "         'max_acc_epoch': 0}\n",
    "global_count = 0\n",
    "writer = SummaryWriter(comment=args.save_path)\n",
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-01T13:51:34.830444300Z",
     "start_time": "2024-09-01T13:51:34.781447100Z"
    }
   },
   "id": "1749d40511748605"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a2e04b83e717a5f"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "9"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-01T13:51:35.827768700Z",
     "start_time": "2024-09-01T13:51:35.659024600Z"
    }
   },
   "id": "3c62709f5f4d5cf8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for epoch in range(1, args.max_epoch + 1):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    # lr_scheduler.step()\n",
    "    # dense_predict_network_scheduler.step()\n",
    "    model.train()\n",
    "    dense_predict_network.train()\n",
    "    tl = Averager()\n",
    "    ta = Averager()\n",
    "\n",
    "    for i, batch in enumerate(train_loader, 1):\n",
    "        optimizer.zero_grad()\n",
    "        dense_predict_network_optim.zero_grad()\n",
    "        global_count = global_count + 1\n",
    "        # if torch.cuda.is_available():\n",
    "        #     data, _ = [_.cuda() for _ in batch]\n",
    "        # else:\n",
    "        data = batch[0]\n",
    "        labels = batch[1]\n",
    "        \n",
    "        p = args.shot * args.way\n",
    "        \n",
    "        data_shot, data_query = data[:p], data[p:]\n",
    "        labels_shot, labels_query = labels[:p],labels[p:]\n",
    "        \n",
    "        feat_shot, feat_query = model(data_shot, data_query)\n",
    "        results, _ = dense_predict_network(feat_query, feat_shot, args)\n",
    "        results = torch.cat(results, dim=0)  # Q x S\n",
    "        # label = torch.arange(args.way).repeat(args.query).long().to('cuda')\n",
    "        label = torch.arange(args.way).repeat(args.query).long()\n",
    "\n",
    "        eps = 0.1\n",
    "        one_hot = torch.zeros_like(results).scatter(1, label.view(-1, 1), 1)\n",
    "        one_hot = one_hot * (1 - eps) + (1 - one_hot) * eps / (args.way - 1)\n",
    "        log_prb = F.log_softmax(results, dim=1)\n",
    "\n",
    "        loss = -(one_hot * log_prb).sum(dim=1)\n",
    "        loss = loss.mean()\n",
    "\n",
    "        acc = count_acc(results.data, label)\n",
    "        writer.add_scalar('data/loss', float(loss), global_count)\n",
    "        writer.add_scalar('data/acc', float(acc), global_count)\n",
    "        print('epoch {}, train {}/{}, loss={:.4f} acc={:.4f}'.format(epoch, i, len(train_loader), loss.item(), acc))\n",
    "\n",
    "        tl.add(loss.item())\n",
    "        ta.add(acc)\n",
    "\n",
    "        loss_total = loss\n",
    "\n",
    "        loss_total.backward()\n",
    "        optimizer.step()\n",
    "        dense_predict_network_optim.step()\n",
    "\n",
    "    lr_scheduler.step()\n",
    "    dense_predict_network_scheduler.step()\n",
    "\n",
    "    tl = tl.item()\n",
    "    ta = ta.item()\n",
    "\n",
    "    model.eval()\n",
    "    dense_predict_network.eval()\n",
    "\n",
    "    vl = Averager()\n",
    "    va = Averager()\n",
    "\n",
    "    print('best epoch {}, best val acc={:.4f}'.format(trlog['max_acc_epoch'], trlog['max_acc']))\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(val_loader, 1):\n",
    "            # if torch.cuda.is_available():\n",
    "            #     data, _ = [_.cuda() for _ in batch]\n",
    "            # else:\n",
    "            data = batch[0]\n",
    "            p = args.shot * args.test_way\n",
    "            data_shot, data_query = data[:p], data[p:]\n",
    "            feat_shot, feat_query = model(data_shot, data_query)\n",
    "\n",
    "            results, _ = dense_predict_network(feat_query, feat_shot, args)  # Q x S\n",
    "\n",
    "            results = [torch.mean(idx, dim=0, keepdim=True) for idx in results]\n",
    "\n",
    "            results = torch.cat(results, dim=0)  # Q x S\n",
    "            # label = torch.arange(args.test_way).repeat(args.query).long().to('cuda')\n",
    "            label = torch.arange(args.test_way).repeat(args.query).long()\n",
    "\n",
    "            loss = F.cross_entropy(results, label)\n",
    "            acc = count_acc(results.data, label)\n",
    "            vl.add(loss.item())\n",
    "            va.add(acc)\n",
    "\n",
    "    vl = vl.item()\n",
    "    va = va.item()\n",
    "    writer.add_scalar('data/val_loss', float(vl), epoch)\n",
    "    writer.add_scalar('data/val_acc', float(va), epoch)\n",
    "    print('epoch {}, val, loss={:.4f} acc={:.4f}'.format(epoch, vl, va))\n",
    "\n",
    "    if va >= trlog['max_acc']:\n",
    "        trlog['max_acc'] = va\n",
    "        trlog['max_acc_epoch'] = epoch\n",
    "        save_model('max_acc')\n",
    "\n",
    "    trlog['train_loss'].append(tl)\n",
    "    trlog['train_acc'].append(ta)\n",
    "    trlog['val_loss'].append(vl)\n",
    "    trlog['val_acc'].append(va)\n",
    "\n",
    "    torch.save(trlog, osp.join(args.save_path, 'trlog'))\n",
    "    save_model('epoch-last')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c5f29ba2027d8316"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Testing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d1f2e1024fa6dff"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "CPEA(\n  (fc1): Mlp(\n    (fc1): Linear(in_features=384, out_features=96, bias=True)\n    (act): GELU(approximate='none')\n    (fc2): Linear(in_features=96, out_features=384, bias=True)\n    (drop): Dropout(p=0.1, inplace=False)\n  )\n  (fc_norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n  (fc2): Mlp(\n    (fc1): Linear(in_features=38416, out_features=256, bias=True)\n    (act): GELU(approximate='none')\n    (fc2): Linear(in_features=256, out_features=1, bias=True)\n    (drop): Dropout(p=0.1, inplace=False)\n  )\n)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trlog = torch.load(osp.join(args.save_path, 'trlog'))\n",
    "test_set = Dataset('test', args)\n",
    "sampler = CategoriesSampler(test_set.label, 50, args.test_way, args.shot + args.query)\n",
    "loader = DataLoader(test_set, batch_sampler=sampler, num_workers=8, pin_memory=True)\n",
    "test_acc_record = np.zeros((50,))\n",
    "\n",
    "model.load_state_dict(torch.load(osp.join(args.save_path, 'max_acc' + '.pth'))['params'])\n",
    "model.eval()\n",
    "\n",
    "dense_predict_network.load_state_dict(\n",
    "    torch.load(osp.join(args.save_path, 'max_acc' + '_dense_predict.pth'))['params'])\n",
    "dense_predict_network.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-31T18:33:04.651464800Z",
     "start_time": "2024-08-31T18:32:49.340773600Z"
    }
   },
   "id": "e683b7948073d4b5"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1: acc 48.00(48.00)\n",
      "batch 2: acc 50.67(53.33)\n",
      "batch 3: acc 49.33(46.67)\n",
      "batch 4: acc 50.00(52.00)\n",
      "batch 5: acc 46.40(32.00)\n",
      "batch 6: acc 47.56(53.33)\n",
      "batch 7: acc 47.43(46.67)\n",
      "batch 8: acc 46.83(42.67)\n",
      "batch 9: acc 47.70(54.67)\n",
      "batch 10: acc 47.20(42.67)\n",
      "batch 11: acc 47.27(48.00)\n",
      "batch 12: acc 48.33(60.00)\n",
      "batch 13: acc 48.51(50.67)\n",
      "batch 14: acc 48.76(52.00)\n",
      "batch 15: acc 48.36(42.67)\n",
      "batch 16: acc 49.00(58.67)\n",
      "batch 17: acc 49.02(49.33)\n",
      "batch 18: acc 48.44(38.67)\n",
      "batch 19: acc 47.72(34.67)\n",
      "batch 20: acc 47.80(49.33)\n",
      "batch 21: acc 48.70(66.67)\n",
      "batch 22: acc 47.88(30.67)\n",
      "batch 23: acc 47.77(45.33)\n",
      "batch 24: acc 48.11(56.00)\n",
      "batch 25: acc 47.36(29.33)\n",
      "batch 26: acc 47.13(41.33)\n",
      "batch 27: acc 47.60(60.00)\n",
      "batch 28: acc 48.48(72.00)\n",
      "batch 29: acc 48.51(49.33)\n",
      "batch 30: acc 49.20(69.33)\n",
      "batch 31: acc 49.08(45.33)\n",
      "batch 32: acc 49.71(69.33)\n",
      "batch 33: acc 49.98(58.67)\n",
      "batch 34: acc 50.04(52.00)\n",
      "batch 35: acc 50.29(58.67)\n",
      "batch 36: acc 49.96(38.67)\n",
      "batch 37: acc 50.09(54.67)\n",
      "batch 38: acc 50.11(50.67)\n",
      "batch 39: acc 50.29(57.33)\n",
      "batch 40: acc 50.40(54.67)\n",
      "batch 41: acc 49.89(29.33)\n",
      "batch 42: acc 50.16(61.33)\n",
      "batch 43: acc 50.14(49.33)\n",
      "batch 44: acc 50.39(61.33)\n",
      "batch 45: acc 50.58(58.67)\n",
      "batch 46: acc 50.81(61.33)\n",
      "batch 47: acc 50.38(30.67)\n",
      "batch 48: acc 50.36(49.33)\n",
      "batch 49: acc 50.23(44.00)\n",
      "batch 50: acc 50.11(44.00)\n",
      "Val Best Epoch 2, Acc 0.4488\n",
      "Test Acc 50.1067 + 2.8771\n"
     ]
    }
   ],
   "source": [
    "ave_acc = Averager()\n",
    "label = torch.arange(args.test_way).repeat(args.query)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(loader, 1):\n",
    "        \n",
    "        # if torch.cuda.is_available():\n",
    "        #     data, _ = [_.cuda() for _ in batch]\n",
    "        # else:\n",
    "        data = batch[0]\n",
    "        k = args.test_way * args.shot\n",
    "        data_shot, data_query = data[:k], data[k:]\n",
    "        feat_shot, feat_query = model(data_shot, data_query)\n",
    "\n",
    "        results, _ = dense_predict_network(feat_query, feat_shot, args)  # Q x S\n",
    "        results = [torch.mean(idx, dim=0, keepdim=True) for idx in results]\n",
    "        results = torch.cat(results, dim=0)  # Q x S\n",
    "        # label = torch.arange(args.test_way).repeat(args.query).long().to('cuda')\n",
    "        label = torch.arange(args.test_way).repeat(args.query).long()\n",
    "\n",
    "        acc = count_acc(results.data, label)\n",
    "        ave_acc.add(acc)\n",
    "        test_acc_record[i - 1] = acc\n",
    "        print('batch {}: acc {:.2f}({:.2f})'.format(i, ave_acc.item() * 100, acc * 100))\n",
    "\n",
    "m, pm = compute_confidence_interval(test_acc_record)\n",
    "print('Val Best Epoch {}, Acc {:.4f}'.format(trlog['max_acc_epoch'], trlog['max_acc']))\n",
    "print('Test Acc {:.4f} + {:.4f}'.format(m * 100, pm * 100))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-31T18:45:08.645212800Z",
     "start_time": "2024-08-31T18:33:05.577325800Z"
    }
   },
   "id": "9c84b74f38b6ad4f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
